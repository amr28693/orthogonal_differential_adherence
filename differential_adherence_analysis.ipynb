{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8760764",
   "metadata": {},
   "source": [
    "# Differential Adherence Framework: Orthogonal Decomposition vs Sum-Score Flattening\n",
    "\n",
    "**By:** Anderson M. Rodriguez  \n",
    "**Repository:** [github.com/amr28693/orthogonal_differential_adherence](https://github.com/amr28693/orthogonal_differential_adherence)\n",
    "\n",
    "Demonstrates that the Differential Adherence Index (Δ = intentional − unintentional)\n",
    "captures statistically significant clinical heterogeneity that sum-scoring\n",
    "(as used by MMAS and similar instruments) provably destroys.\n",
    "\n",
    "**Data:** NeuroGerAd study (N=907 neurological patients)  \n",
    "Prell et al. (2022) *Sci Data* 9, 734. [doi:10.1038/s41597-022-01847-9](https://doi.org/10.1038/s41597-022-01847-9)  \n",
    "Available: [https://osf.io/kuaph/](https://osf.io/kuaph/)\n",
    "\n",
    "**Instrument:** SAMS (Stendal Adherence to Medication Score) — 18 items, 0–4 Likert  \n",
    "Sub-factors per validated 3-factor CFA (Prell et al. 2022):\n",
    "- Forgetting (unintentional): items 6, 14, 15, 16, 18\n",
    "- Intentional modification: items 4, 7, 8, 9, 10, 11, 12, 13, 17\n",
    "- Missing knowledge: items 1, 2, 3, 5\n",
    "\n",
    "**Outputs:**\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `fig1_3d_vs_sumscore.png` | 3D decomposition vs honest 1D sum-score strip |\n",
    "| `fig2_group_heterogeneity.png` | Δ distributions + group comparisons |\n",
    "| `fig3_information_loss.png` | Orthogonality + F-statistic comparison |\n",
    "| `results_summary.txt` | All statistical results |\n",
    "\n",
    "Following this notebook, run `sensitivity_analysis.py` for Table 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fe374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "DATA_FILE = 'NeuroGerAd_Data_OSF.xlsx'\n",
    "FIGURE_DPI = 300\n",
    "\n",
    "# SAMS sub-factor item mapping (validated 3-factor CFA, Prell et al. 2022)\n",
    "# Scale: 0 = \"never\" to 4 = \"most of the time\" (higher = more nonadherent)\n",
    "UNINTENTIONAL_ITEMS = ['sams_6', 'sams_14', 'sams_15', 'sams_16', 'sams_18']\n",
    "INTENTIONAL_ITEMS   = ['sams_4', 'sams_7', 'sams_8', 'sams_9', 'sams_10',\n",
    "                       'sams_11', 'sams_12', 'sams_13', 'sams_17']\n",
    "KNOWLEDGE_ITEMS     = ['sams_1', 'sams_2', 'sams_3', 'sams_5']\n",
    "DIAGNOSIS_COL       = 'diagnosis_collapsed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf09a21",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load NeuroGerAd Excel file and compute sub-factor means.\"\"\"\n",
    "    filepath = os.path.join(os.path.dirname(os.path.abspath('.')), DATA_FILE)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath = DATA_FILE\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"ERROR: Cannot find '{DATA_FILE}'\")\n",
    "        print(f\"Place NeuroGerAd_Data_OSF.xlsx in the same folder as this notebook.\")\n",
    "        print(f\"Download from: https://osf.io/kuaph/\")\n",
    "        raise FileNotFoundError(DATA_FILE)\n",
    "\n",
    "    print(f\"Loading: {filepath}\")\n",
    "    raw = pd.read_excel(filepath)\n",
    "    print(f\"  Raw: {len(raw)} rows, {len(raw.columns)} columns\")\n",
    "\n",
    "    # Sub-factor means (means, not sums — comparable across unequal item counts)\n",
    "    # Person-mean scoring: average available items per subscale (skipna=True).\n",
    "    # Standard approach when items within a subscale are parallel indicators.\n",
    "    # Participants are retained if they have >= 1 item answered per subscale.\n",
    "    # Sensitivity analysis under stricter thresholds: see sensitivity_analysis.py.\n",
    "    raw['unintentional'] = raw[UNINTENTIONAL_ITEMS].mean(axis=1, skipna=True)\n",
    "    raw['intentional']   = raw[INTENTIONAL_ITEMS].mean(axis=1, skipna=True)\n",
    "    raw['knowledge']     = raw[KNOWLEDGE_ITEMS].mean(axis=1, skipna=True)\n",
    "    raw['group']         = raw[DIAGNOSIS_COL]\n",
    "\n",
    "    df = raw.dropna(subset=['unintentional', 'intentional', 'group']).copy()\n",
    "    print(f\"  Valid: {len(df)} (dropped {len(raw) - len(df)} with all items missing in a subscale or missing diagnosis)\")\n",
    "\n",
    "    # Core computed variables\n",
    "    df['delta']      = df['intentional'] - df['unintentional']\n",
    "    df['mmas_proxy'] = df['intentional'] + df['unintentional']\n",
    "    df['direction']  = np.where(df['delta'] >= 0,\n",
    "                                'Intentional-dominant', 'Unintentional-dominant')\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29bfac",
   "metadata": {},
   "source": [
    "## 2. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d747558",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []\n",
    "log.append(\"Differential Adherence Analysis -- NeuroGerAd Real Data\")\n",
    "log.append(f\"Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "log.append(\"\")\n",
    "log.append(f\"Data loaded: N={len(df)}, {df['group'].nunique()} diagnosis groups\\n\")\n",
    "\n",
    "def print_descriptives(df, log):\n",
    "    \\\"\\\"\\\"Print and log descriptive statistics.\\\"\\\"\\\"\n",
    "    lines = []\n",
    "    lines.append(\"=\" * 72)\n",
    "    lines.append(\"DESCRIPTIVE STATISTICS\")\n",
    "    lines.append(\"=\" * 72)\n",
    "    lines.append(f\"N = {len(df)}\")\n",
    "    lines.append(f\"Diagnosis groups: {dict(df['group'].value_counts())}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Sub-factor means (0-4 scale, higher = more nonadherent):\")\n",
    "    lines.append(f\"  Unintentional (forgetting, 5 items):  \"\n",
    "                 f\"M = {df['unintentional'].mean():.3f}, SD = {df['unintentional'].std():.3f}\")\n",
    "    lines.append(f\"  Intentional (modification, 9 items):  \"\n",
    "                 f\"M = {df['intentional'].mean():.3f}, SD = {df['intentional'].std():.3f}\")\n",
    "    lines.append(f\"  Missing knowledge (4 items):          \"\n",
    "                 f\"M = {df['knowledge'].mean():.3f}, SD = {df['knowledge'].std():.3f}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Differential Adherence Index (delta = intentional - unintentional):\")\n",
    "    lines.append(f\"  Mean = {df['delta'].mean():.3f}, SD = {df['delta'].std():.3f}\")\n",
    "    lines.append(f\"  Range = [{df['delta'].min():.3f}, {df['delta'].max():.3f}]\")\n",
    "    lines.append(f\"  Intentional-dominant (delta >= 0): \"\n",
    "                 f\"{(df['delta'] >= 0).sum()} ({(df['delta'] >= 0).mean()*100:.1f}%)\")\n",
    "    lines.append(f\"  Unintentional-dominant (delta < 0): \"\n",
    "                 f\"{(df['delta'] < 0).sum()} ({(df['delta'] < 0).mean()*100:.1f}%)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Sum-score proxy (MMAS-like = intentional + unintentional):\")\n",
    "    lines.append(f\"  Mean = {df['mmas_proxy'].mean():.3f}, SD = {df['mmas_proxy'].std():.3f}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"-\" * 72)\n",
    "    lines.append(\"GROUP-LEVEL STATISTICS\")\n",
    "    lines.append(\"-\" * 72)\n",
    "    hdr = f\"{'Group':<28} {'N':>5} {'\\u0394 Mean':>8} {'\\u0394 SD':>7} {'%Int':>6} {'Sum Mean':>9} {'Sum SD':>7}\"\n",
    "    lines.append(hdr)\n",
    "    lines.append(\"-\" * 72)\n",
    "    for g in sorted(df['group'].unique()):\n",
    "        sub = df[df['group'] == g]\n",
    "        lines.append(f\"{g:<28} {len(sub):>5} {sub['delta'].mean():>8.3f} \"\n",
    "                     f\"{sub['delta'].std():>7.3f} \"\n",
    "                     f\"{(sub['delta'] >= 0).mean()*100:>5.1f} \"\n",
    "                     f\"{sub['mmas_proxy'].mean():>9.3f} \"\n",
    "                     f\"{sub['mmas_proxy'].std():>7.3f}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    text = \"\\n\".join(lines)\n",
    "    print(text)\n",
    "    log.append(text)\n",
    "\n",
    "print_descriptives(df, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29a79a",
   "metadata": {},
   "source": [
    "## 3. Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_label(p):\n",
    "    if p < 0.001: return \"***\"\n",
    "    if p < 0.01:  return \"**\"\n",
    "    if p < 0.05:  return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "\n",
    "def run_statistics(df, log):\n",
    "    \\\"\\\"\\\"Run and log all statistical tests. Returns dict of key results.\\\"\\\"\\\"\n",
    "    lines = []\n",
    "    lines.append(\"=\" * 72)\n",
    "    lines.append(\"STATISTICAL TESTS\")\n",
    "    lines.append(\"=\" * 72)\n",
    "\n",
    "    # Orthogonality\n",
    "    r, p = stats.pearsonr(df['mmas_proxy'], df['delta'])\n",
    "    lines.append(\"Orthogonality (Pearson correlation, sum vs delta):\")\n",
    "    lines.append(f\"  r = {r:.3f}, p = {p:.4f}\")\n",
    "    lines.append(f\"  Shared variance (r\\u00b2): {r**2*100:.1f}%\")\n",
    "    lines.append(f\"  -> {'Near-perfect orthogonality confirmed' if abs(r) < 0.1 else 'Some shared variance'}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # ANOVA\n",
    "    groups = sorted(df['group'].unique())\n",
    "    k, n = len(groups), len(df)\n",
    "    grp_delta = [df[df['group'] == g]['delta'].values for g in groups]\n",
    "    grp_mmas  = [df[df['group'] == g]['mmas_proxy'].values for g in groups]\n",
    "\n",
    "    f_d, p_d = stats.f_oneway(*grp_delta)\n",
    "    f_m, p_m = stats.f_oneway(*grp_mmas)\n",
    "    eta_d = (f_d * (k-1)) / (f_d * (k-1) + (n-k))\n",
    "    eta_m = (f_m * (k-1)) / (f_m * (k-1) + (n-k))\n",
    "\n",
    "    lines.append(\"One-way ANOVA by diagnosis group:\")\n",
    "    lines.append(f\"  delta (differential):  F({k-1},{n-k}) = {f_d:.2f}, \"\n",
    "                 f\"p = {p_d:.4f} {sig_label(p_d)}, eta2 = {eta_d:.4f}\")\n",
    "    lines.append(f\"  Sum (MMAS-like):       F({k-1},{n-k}) = {f_m:.2f},  \"\n",
    "                 f\"p = {p_m:.4f} {sig_label(p_m)}, eta2 = {eta_m:.4f}\")\n",
    "    lines.append(\"\")\n",
    "    if p_d < 0.05 and p_m >= 0.05:\n",
    "        lines.append(\"  * Groups differ significantly on delta but NOT on sum-score.\")\n",
    "        lines.append(\"    Sum-scoring destroys individual-level directionality (many-to-one projection).\")\n",
    "    elif eta_d > eta_m:\n",
    "        lines.append(f\"  -> delta captures {eta_d/max(eta_m,1e-6):.1f}x more \"\n",
    "                     f\"between-group variance than sum-score\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Pairwise t-tests\n",
    "    lines.append(\"Pairwise comparisons on delta (independent samples t-test):\")\n",
    "    lines.append(f\"  {'Comparison':<50} {'t':>7} {'p':>8} {'|d|':>7} {'sig':>4}\")\n",
    "    lines.append(\"  \" + \"-\" * 76)\n",
    "    for i in range(len(groups)):\n",
    "        for j in range(i+1, len(groups)):\n",
    "            g1, g2 = groups[i], groups[j]\n",
    "            d1 = df[df['group'] == g1]['delta'].values\n",
    "            d2 = df[df['group'] == g2]['delta'].values\n",
    "            t_stat, p_val = stats.ttest_ind(d1, d2)\n",
    "            pooled_sd = np.sqrt((d1.std()**2 + d2.std()**2) / 2)\n",
    "            d_val = abs((d1.mean() - d2.mean()) / pooled_sd) if pooled_sd > 0 else 0\n",
    "            label = f\"{g1} vs {g2}\"\n",
    "            lines.append(f\"  {label:<50} {t_stat:>7.2f} \"\n",
    "                         f\"{p_val:>8.4f} {d_val:>7.2f} {sig_label(p_val):>4}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    text = \"\\n\".join(lines)\n",
    "    print(text)\n",
    "    log.append(text)\n",
    "\n",
    "    return dict(r=r, r_p=p, f_delta=f_d, p_delta=p_d, eta_delta=eta_d,\n",
    "                f_mmas=f_m, p_mmas=p_m, eta_mmas=eta_m, k=k, n=n)\n",
    "\n",
    "sr = run_statistics(df, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a8629",
   "metadata": {},
   "source": [
    "## 4. Figure 1: 3D Decomposition vs Sum-Score Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 7))\n",
    "\n",
    "# --- Panel A: 3D orthogonal decomposition ---\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "colors = np.where(df['delta'] >= 0, '#e74c3c', '#3498db')\n",
    "ax1.scatter(df['unintentional'], df['intentional'], df['delta'],\n",
    "            c=colors, s=8, alpha=0.45, edgecolors='none')\n",
    "\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(df['unintentional'].min(), df['unintentional'].max(), 5),\n",
    "    np.linspace(df['intentional'].min(), df['intentional'].max(), 5))\n",
    "ax1.plot_surface(xx, yy, np.zeros_like(xx), alpha=0.06, color='gray')\n",
    "\n",
    "ax1.set_xlabel('Unintentional\\n(Forgetting)', fontsize=10)\n",
    "ax1.set_ylabel('Intentional\\n(Modification)', fontsize=10)\n",
    "ax1.set_zlabel(r'$\\Delta$', fontsize=11)\n",
    "ax1.set_title(f'A) Orthogonal Decomposition (N={len(df)})',\n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.view_init(elev=22, azim=45)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#e74c3c',\n",
    "           markersize=7, label=r'Intentional-dominant ($\\Delta \\geq 0$)'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#3498db',\n",
    "           markersize=7, label=r'Unintentional-dominant ($\\Delta < 0$)')]\n",
    "ax1.legend(handles=legend_elements, loc='upper left', fontsize=7.5)\n",
    "\n",
    "# --- Panel B: What sum-scoring actually gives you ---\n",
    "ax2 = fig.add_subplot(122)\n",
    "jitter = np.random.default_rng(42).normal(0, 0.015, len(df))\n",
    "ax2.scatter(df['mmas_proxy'], jitter,\n",
    "            c='#7f8c8d', s=6, alpha=0.25, edgecolors='none')\n",
    "\n",
    "ax2.set_xlabel('Sum-Score (Intentional + Unintentional)', fontsize=11)\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylim(-0.08, 0.08)\n",
    "ax2.set_title('B) Sum-Score Reduction (what you actually get)',\n",
    "              fontsize=12, fontweight='bold')\n",
    "ax2.text(0.97, 0.03, 'No color or direction.\\nSimple single number.',\n",
    "         transform=ax2.transAxes, ha='right', va='bottom',\n",
    "         fontsize=9, color='#666', fontstyle='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig1_3d_vs_sumscore.png', dpi=FIGURE_DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: fig1_3d_vs_sumscore.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea10c9e",
   "metadata": {},
   "source": [
    "## 5. Figure 2: Group-Level Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59998600",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = sorted(df['group'].unique())\n",
    "gc = dict(zip(groups, plt.cm.Set2(np.linspace(0, 1, len(groups)))))\n",
    "gm = df.groupby('group')[['unintentional', 'intentional',\n",
    "                           'delta', 'mmas_proxy']].mean()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5.5))\n",
    "\n",
    "# --- A: delta distributions ---\n",
    "ax = axes[0]\n",
    "for g in groups:\n",
    "    sub = df[df['group'] == g]\n",
    "    ax.hist(sub['delta'], bins=30, alpha=0.4,\n",
    "            label=f\"{g} ({len(sub)})\", color=gc[g], density=True)\n",
    "ax.axvline(0, color='black', linestyle='--', alpha=0.4, lw=0.8)\n",
    "ax.set_xlabel(r'$\\Delta$ (intentional $-$ unintentional)', fontsize=10)\n",
    "ax.set_ylabel('Density', fontsize=10)\n",
    "ax.set_title(r'A) $\\Delta$ Distribution by Diagnosis',\n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=6.5, loc='upper right', framealpha=0.7)\n",
    "\n",
    "# --- B: Group means — sum-score view ---\n",
    "ax = axes[1]\n",
    "for score in np.arange(0.3, 1.5, 0.15):\n",
    "    xl = np.linspace(0, score, 100)\n",
    "    yl = score - xl\n",
    "    m = (xl >= 0.1) & (yl >= 0.05)\n",
    "    if m.any():\n",
    "        ax.plot(xl[m], yl[m], '-', color='#ccc', alpha=0.3, lw=0.7)\n",
    "for g in groups:\n",
    "    row = gm.loc[g]\n",
    "    ax.scatter(row['unintentional'], row['intentional'],\n",
    "               c=[gc[g]], s=160, zorder=5, edgecolors='black', linewidth=1)\n",
    "    ax.annotate(g, (row['unintentional'] + 0.008,\n",
    "                    row['intentional'] + 0.008), fontsize=7)\n",
    "ax.set_xlabel('Unintentional (mean)', fontsize=10)\n",
    "ax.set_ylabel('Intentional (mean)', fontsize=10)\n",
    "ax.set_title(f\"B) Sum-Score View: F={sr['f_mmas']:.2f}, p={sr['p_mmas']:.3f}\",\n",
    "             fontsize=11, fontweight='bold')\n",
    "\n",
    "# --- C: Group delta bar chart ---\n",
    "ax = axes[2]\n",
    "sorted_gm = gm.sort_values('delta')\n",
    "for i, (g, row) in enumerate(sorted_gm.iterrows()):\n",
    "    ax.barh(i, row['delta'], color=gc[g], edgecolor='black',\n",
    "            linewidth=0.5, height=0.6)\n",
    "    n_g = len(df[df['group'] == g])\n",
    "    offset = 0.008 if row['delta'] < 0 else -0.008\n",
    "    ha = 'right' if row['delta'] < 0 else 'left'\n",
    "    ax.text(row['delta'] + offset, i, f'n={n_g}',\n",
    "            fontsize=7.5, va='center', ha=ha, color='#444')\n",
    "ax.axvline(0, color='black', linestyle='-', alpha=0.4, lw=0.8)\n",
    "ax.set_yticks(range(len(sorted_gm)))\n",
    "ax.set_yticklabels(sorted_gm.index, fontsize=9)\n",
    "ax.set_xlabel(r'Mean $\\Delta$', fontsize=10)\n",
    "ax.set_title(r'C) $\\Delta$ by Diagnosis: F={:.2f}, p={:.3f}*'.format(\n",
    "             sr['f_delta'], sr['p_delta']),\n",
    "             fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig2_group_heterogeneity.png', dpi=FIGURE_DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: fig2_group_heterogeneity.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209a76a",
   "metadata": {},
   "source": [
    "## 6. Figure 3: Information Loss Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5.5))\n",
    "\n",
    "# --- A: Orthogonality scatter ---\n",
    "ax = axes[0]\n",
    "colors = np.where(df['delta'] >= 0, '#e74c3c', '#3498db')\n",
    "ax.scatter(df['mmas_proxy'], df['delta'], c=colors, s=6, alpha=0.3,\n",
    "           edgecolors='none')\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.25, lw=0.7)\n",
    "ax.text(0.03, 0.97,\n",
    "        f\"r = {sr['r']:.3f}\\n{(1-sr['r']**2)*100:.1f}% independent\",\n",
    "        transform=ax.transAxes, fontsize=9, va='top',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white',\n",
    "                  edgecolor='#ccc', alpha=0.85))\n",
    "ax.set_xlabel('Sum-Score', fontsize=11)\n",
    "ax.set_ylabel(r'$\\Delta$', fontsize=11)\n",
    "ax.set_title(r'A) Orthogonality: Sum vs $\\Delta$',\n",
    "             fontsize=12, fontweight='bold')\n",
    "\n",
    "# --- B: F-statistic comparison ---\n",
    "ax = axes[1]\n",
    "labels = ['Sum-Score', r'$\\Delta$']\n",
    "f_vals = [sr['f_mmas'], sr['f_delta']]\n",
    "p_vals = [sr['p_mmas'], sr['p_delta']]\n",
    "bar_colors = ['#bdc3c7', '#2ecc71']\n",
    "\n",
    "bars = ax.bar(labels, f_vals, color=bar_colors, edgecolor='black',\n",
    "              linewidth=0.8, width=0.4)\n",
    "for bar, fv, pv in zip(bars, f_vals, p_vals):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.06,\n",
    "            f'F={fv:.2f}\\np={pv:.3f} {sig_label(pv)}',\n",
    "            ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "f_crit = stats.f.ppf(0.95, sr['k'] - 1, sr['n'] - sr['k'])\n",
    "ax.axhline(y=f_crit, color='red', linestyle=':', alpha=0.4, lw=1,\n",
    "           label=f'p=.05 (F={f_crit:.2f})')\n",
    "ax.set_ylabel('F-statistic (ANOVA by diagnosis)', fontsize=11)\n",
    "ax.set_title('B) Between-Group Signal', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=8, loc='upper left')\n",
    "ax.set_ylim(0, max(f_vals) * 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig3_information_loss.png', dpi=FIGURE_DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: fig3_information_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d0c69",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34774d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_summary.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(log))\n",
    "print(\"Saved: results_summary.txt\")\n",
    "print(\"\\nPrimary analysis complete.\")\n",
    "print(\"Next: run sensitivity_analysis.py for Table 2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
